{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tarea2_V2.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "CWfEI8Oxnv6j",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "a5e76fc5-2f63-4ede-f05b-1cf2dd7c8ef2"
      },
      "source": [
        "#Estas lineas corren solo en google colab:\n",
        "import os.path \n",
        "try:\n",
        "  import google.colab\n",
        "  !pip install gpustat\n",
        "  IN_COLAB = True\n",
        "except:\n",
        "  IN_COLAB = False\n",
        "if IN_COLAB:\n",
        "  if os.path.exists('/content/ChestXRay2017.zip'):\n",
        "    print(\"Datos ya descargados\")\n",
        "  else:\n",
        "    !wget https://data.mendeley.com/datasets/rscbjbr9sj/2/files/f12eaf6d-6023-432f-acc9-80c9d7393433/ChestXRay2017.zip\n",
        "    !unzip /content/ChestXRay2017.zip"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gpustat in /usr/local/lib/python3.6/dist-packages (0.6.0)\n",
            "Requirement already satisfied: six>=1.7 in /usr/local/lib/python3.6/dist-packages (from gpustat) (1.12.0)\n",
            "Requirement already satisfied: blessings>=1.6 in /usr/local/lib/python3.6/dist-packages (from gpustat) (1.7)\n",
            "Requirement already satisfied: nvidia-ml-py3>=7.352.0 in /usr/local/lib/python3.6/dist-packages (from gpustat) (7.352.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.6/dist-packages (from gpustat) (5.4.8)\n",
            "Datos ya descargados\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N08D-4ID52W7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "outputId": "1af61dbd-37e7-4145-8f4c-d8046e8dfd62"
      },
      "source": [
        "!pip install torchvision\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (0.6.1+cu101)\n",
            "Requirement already satisfied: torch==1.5.1 in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.5.1+cu101)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision) (7.0.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.18.5)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch==1.5.1->torchvision) (0.16.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mfoNboyIolBF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torchvision.datasets.folder import default_loader\n",
        "\n",
        "# Intento de usar el train_model de https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html\n",
        "from __future__ import print_function, division\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "import numpy as np\n",
        "import torchvision\n",
        "#from torchvision.transforms.functional import convert_image_dtype\n",
        "from torchvision import datasets, models, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import os\n",
        "import copy"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SR3_62kTskvH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "2eb7c747-e23a-4ece-f9db-b1bd45addab0"
      },
      "source": [
        "# Torchvision transforms compose para carga de datos con transformacion:\n",
        "root = '/content/chest_xray/train/'\n",
        "\n",
        "degrees = (-20,20)\n",
        "transformer = torchvision.transforms.Compose([        \n",
        "    torchvision.transforms.Resize(size = (224,224)),\n",
        "    torchvision.transforms.RandomHorizontalFlip(p=0.5),\n",
        "    torchvision.transforms.RandomRotation(degrees),\n",
        "    torchvision.transforms.ColorJitter(brightness=[1.2, 1.5]),\n",
        "    torchvision.transforms.ToTensor(), \n",
        "    ])\n",
        "\n",
        "# Data augmentation and normalization for training\n",
        "# Just normalization for validation\n",
        "data_transforms = {\n",
        "    'train': transforms.Compose([               \n",
        "    torchvision.transforms.Resize(size = (224,224)),\n",
        "    torchvision.transforms.RandomHorizontalFlip(p=0.5),\n",
        "    torchvision.transforms.RandomRotation(degrees),\n",
        "    torchvision.transforms.ColorJitter(brightness=[1.2, 1.5]),\n",
        "    torchvision.transforms.ToTensor()\n",
        "    #torchvision.transforms.functional.convert_image_dtype(dtype = torch.float16)\n",
        "    ]),\n",
        "    'val': transforms.Compose([\n",
        "    torchvision.transforms.Resize(size = (224,224)),\n",
        "    torchvision.transforms.RandomHorizontalFlip(p=0.5),\n",
        "    torchvision.transforms.RandomRotation(degrees),\n",
        "    torchvision.transforms.ColorJitter(brightness=[1.2, 1.5]),\n",
        "    torchvision.transforms.ToTensor()\n",
        "    #torchvision.transforms.functional.convert_image_dtype(dtype = torch.float16)\n",
        "    ]),\n",
        "}\n",
        "# /content/chest_xray/\n",
        "data_dir = '/content/chest_xray'\n",
        "# rename test to val:\n",
        "!mv /content/chest_xray/test /content/chest_xray/val\n",
        "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n",
        "                                          data_transforms[x])\n",
        "                  for x in ['train', 'val']}\n",
        "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=16,\n",
        "                                             shuffle=True, num_workers=4)\n",
        "              for x in ['train', 'val']}\n",
        "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
        "class_names = image_datasets['train'].classes\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mv: cannot stat '/content/chest_xray/test': No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y_n6BBPnCBv8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "9aa7b6f9-22eb-4134-cc4f-6f39fb367f72"
      },
      "source": [
        "torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "npe33J3HpR8c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#1 \n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "torch.manual_seed(2020)\n",
        "\n",
        "\n",
        "class DWSepConv2d(nn.Module):\n",
        "    \n",
        "    def __init__(self,in_channels, out_channels, kernel_size,padding,bias=True):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels,kernel_size,padding=padding,bias=bias)\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels,kernel_size=1,padding=padding,bias=bias)\n",
        "    def forward(self,xb):\n",
        "        xb = F.relu(self.conv1(xb.float()))\n",
        "        xb = F.relu(self.conv2(xb)) \n",
        "        return xb"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OPysTn8MpR8m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#2\n",
        "import torch.nn.functional as F\n",
        "from torch import nn\n",
        "class VGG16DWSep(nn.Module):\n",
        "    \n",
        "    def __init__(self,in_channels):\n",
        "        super().__init__()\n",
        "        # bloque 1\n",
        "        self.conv1 = nn.Conv2d(in_channels,64,kernel_size=3,padding=1,stride=1)\n",
        "        self.conv2 = nn.Conv2d(64,64,kernel_size=3, padding=1, stride=1)\n",
        "        self.maxpool1 = nn.MaxPool2d(kernel_size=2,stride=2) \n",
        "        # bloque 2\n",
        "        self.dwconv3 = DWSepConv2d(64,128,kernel_size=3,padding=1)\n",
        "        self.dwconv4 = DWSepConv2d(128,128,kernel_size=3,padding=1)\n",
        "        self.maxpool2 = nn.MaxPool2d(kernel_size=2,stride=2)\n",
        "        # bloque 3        \n",
        "        self.dwconv5 = DWSepConv2d(128,256,kernel_size=3,padding=1)\n",
        "        self.batchnorm1 = nn.BatchNorm2d(256)\n",
        "        # bloque 4\n",
        "        self.dwconv6 = DWSepConv2d(256,256,kernel_size=3,padding=1)\n",
        "        self.batchnorm2 = nn.BatchNorm2d(256)\n",
        "        # bloque 5\n",
        "        self.dwconv7 = DWSepConv2d(256,256,kernel_size=3,padding=1)\n",
        "        self.maxpool3 = nn.MaxPool2d(kernel_size=2,stride=2)\n",
        "        # bloque 6\n",
        "        self.dwconv8 = DWSepConv2d(256,512,kernel_size=3,padding=1)\n",
        "        self.batchnorm3 = nn.BatchNorm2d(512)\n",
        "        # bloque 7\n",
        "        self.dwconv9 = DWSepConv2d(512,512,kernel_size=3,padding=1)\n",
        "        self.batchnorm4 = nn.BatchNorm2d(512)\n",
        "        # bloque 8\n",
        "        self.dwconv10 = DWSepConv2d(512,512,kernel_size=3,padding=1)\n",
        "        self.maxpool4 = nn.MaxPool2d(kernel_size=2,stride=2)\n",
        "        # bloque o1\n",
        "        self.flatten1 = nn.Flatten()\n",
        "        self.lin1 = nn.Linear(184832,1024)\n",
        "        self.drop1 = nn.Dropout(.7)\n",
        "        # bloque o2\n",
        "        self.lin2 = nn.Linear(1024,512)\n",
        "        self.drop2 = nn.Dropout(.5)\n",
        "        self.lin3 = nn.Linear(512,2)\n",
        "    \n",
        "    def forward(self,xb):\n",
        "      # bloque 1\n",
        "      xb = xb.view(-1, 3, 224, 224)\n",
        "      xb = F.relu(self.conv1(xb))\n",
        "      xb = F.relu(self.conv2(xb))\n",
        "      xb = self.maxpool1(xb)\n",
        "      # bloque 2\n",
        "      xb = F.relu(self.dwconv3(xb))\n",
        "      xb = F.relu(self.dwconv4(xb))\n",
        "      xb = self.maxpool2(xb)\n",
        "      # bloque 3\n",
        "      xb = F.relu(self.dwconv5(xb))\n",
        "      xb = F.relu(self.batchnorm1(xb))\n",
        "      # bloque 4\n",
        "      xb = F.relu(self.dwconv6(xb))\n",
        "      xb = F.relu(self.batchnorm2(xb))\n",
        "      # bloque 5\n",
        "      xb = F.relu(self.dwconv7(xb))\n",
        "      xb = self.maxpool3(xb)\n",
        "      # bloque 6\n",
        "      xb = F.relu(self.dwconv8(xb))\n",
        "      xb = F.relu(self.batchnorm3(xb))\n",
        "      # bloque 7\n",
        "      xb = F.relu(self.dwconv9(xb))\n",
        "      xb = F.relu(self.batchnorm4(xb))\n",
        "      # bloque 8\n",
        "      xb = F.relu(self.dwconv10(xb))\n",
        "      xb = self.maxpool4(xb)\n",
        "      #print(xb.shape)\n",
        "      # bloque o1\n",
        "      xb = self.flatten1(xb)\n",
        "      xb = F.relu(self.lin1(xb))\n",
        "      xb = self.drop1(xb)\n",
        "      # bloque o2\n",
        "      xb = F.relu(self.lin2(xb))\n",
        "      xb = self.drop2(xb)\n",
        "      xb = F.relu(self.lin3(xb))\n",
        "      return xb.view(-1, xb.size(1))"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "upmg1u_S6x-P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# Descargamos la red vgg16\n",
        "vgg16 = torchvision.models.vgg16(pretrained=True, progress=True)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5CTq1ZMVofBV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Se quiere la capa 0 y la 2, que son las dos primeras convolucionales:\n",
        "pesos_dict = {\n",
        "    'conv1' : vgg16.features[0],\n",
        "    'conv2' : vgg16.features[2]\n",
        "}"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xxtQetc2sI5F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "net = VGG16DWSep(in_channels = 3)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ZTptthUFKwM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#intento de traspaso de pesos:\n",
        "net.conv1.weight = pesos_dict['conv1'].weight\n",
        "net.conv2.weight = pesos_dict['conv2'].weight"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DUF2tE7lY6sX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Congelamos los pesos de la red vgg16\n",
        "for param in vgg16.parameters():\n",
        "  param.requires_grad = False"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i4WOBRrPFnYg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Congelamos los pesos de las dos primeras capas convoluvionales de la red \n",
        "# (capas que se transfirieron):\n",
        "net.conv1.requires_grad_ = False\n",
        "net.conv2.requires_grad_ = False"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "24JrFRDOXqEQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "1578a468-b8f7-4d7f-dd5c-d4ebaca5cbaa"
      },
      "source": [
        "# Se elimina la red VGG16 para liberar espacio en colab \n",
        "del vgg16\n",
        "torch.cuda.empty_cache()\n",
        "# Show GPU Stat\n",
        "!gpustat -p"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1m\u001b[37me95263fb959d           \u001b[m  Thu Jul 16 21:11:59 2020  \u001b[1m\u001b[30m418.67\u001b[m\n",
            "\u001b[36m[0]\u001b[m \u001b[34mTesla P100-PCIE-16GB\u001b[m |\u001b[1m\u001b[31m 60'C\u001b[m, \u001b[32m  0 %\u001b[m | \u001b[36m\u001b[1m\u001b[33m   10\u001b[m / \u001b[33m16280\u001b[m MB |\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jJaBe8rWF8vw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Clase EarlyStopping\n",
        "# Se requiere la libreria numpy!!\n",
        "import numpy  as np\n",
        "class EarlyStopping():\n",
        "  '''\n",
        "  Regularization heuristic:\n",
        "\n",
        "  '''\n",
        "  def __init__(self, modo='min', paciencia=5, porcentaje:bool = False, tol=0):\n",
        "    '''\n",
        "    Arguments:\n",
        "    ---------\n",
        "    modo: 'min' o 'max'. Si se debe minimizar o maximizar la metrica objetivo\n",
        "    paciancia: Cantidad de epocas en la que la metrica puede empeorar\n",
        "    porcentaje: si la diferencia es relativa (true) o absoluta\n",
        "    tol: diferencia minima que debe existir con respecto la mejor metrica ya\n",
        "        observada  para considerar si existe un empeoramiento del desempeno\n",
        "    '''\n",
        "    self.modo = modo\n",
        "    self.paciencia  = paciencia\n",
        "    self.porcentaje = porcentaje\n",
        "    self.best = np.Inf if self.modo == 'min' else -np.Inf\n",
        "    self.contador = 0\n",
        "    self.tol = tol\n",
        "\n",
        "  \n",
        "  def __compareMin(self, metrica_validacion):\n",
        "    if self.porcentaje:      \n",
        "      # Si la dif relativa es mayor a la tolerada: actualizar contador:\n",
        "      if metrica_validacion < (1-self.tol)*self.best:\n",
        "        self.contador = 0\n",
        "        self.best = metrica_validacion\n",
        "        return True\n",
        "      else:\n",
        "        self.contador +=1\n",
        "        return False\n",
        "    else:\n",
        "      if metrica_validacion < self.best - self.tol:\n",
        "        self.best = metrica_validacion\n",
        "        self.contador = 0\n",
        "        return True\n",
        "      else:\n",
        "        self.contador += 1\n",
        "        return False\n",
        "    \n",
        "    def __comareMax(self, metrica_validacion):\n",
        "      if self.porcentaje:\n",
        "         # Si la dif relativa es mayor a la tolerada: actualizar contador:\n",
        "        if metrica_validacion > (1+self.tol)*self.best:\n",
        "          self.contador = 0\n",
        "          self.best = metrica_validacion\n",
        "          return True\n",
        "        else:\n",
        "          self.contador +=1\n",
        "          return False\n",
        "      else:\n",
        "        if metrica_validacion > self.best + self.tol:\n",
        "          self.best = metrica_validacion\n",
        "          self.contador = 0\n",
        "          return True\n",
        "        else:\n",
        "          self.contador += 1\n",
        "          return False        \n",
        "\n",
        "  # Es necesaria la anotacion??\n",
        "  #@classmethod\n",
        "  def __mejor(self, metrica_validacion):\n",
        "    '''\n",
        "    Compara @metrica_validacion con la mejor ya observada segun las \n",
        "    especificaciones de porcentaje y modo. \n",
        "    '''\n",
        "    if self.modo == 'min':\n",
        "      # Comparar segun el modo y porcentaje:\n",
        "      if self.__compareMin(metrica_validacion):\n",
        "        return True\n",
        "      else:\n",
        "        return False\n",
        "    else:\n",
        "      # Comparar segun el modo y porcentaje:\n",
        "      if self.__compareMax(metrica_validacion):\n",
        "        return True\n",
        "      else:\n",
        "        return False\n",
        "\n",
        "  #@classmethod\n",
        "  def deberia_parar(self, metrica_validacion):\n",
        "    if not self.__mejor(metrica_validacion) and self.contador >= self.paciencia:\n",
        "      return True\n",
        "    else:\n",
        "      return False\n"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1fNrIJwwyBQy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def imshow(inp, title=None):\n",
        "    \"\"\"Imshow for Tensor.\"\"\"\n",
        "    inp = inp.numpy().transpose((1, 2, 0))\n",
        "    mean = np.array([0.485, 0.456, 0.406])\n",
        "    std = np.array([0.229, 0.224, 0.225])\n",
        "    inp = std * inp + mean\n",
        "    inp = np.clip(inp, 0, 1)\n",
        "    plt.imshow(inp)\n",
        "    if title is not None:\n",
        "        plt.title(title)\n",
        "    plt.pause(0.001)  # pause a bit so that plots are updated\n",
        "\n",
        "\n",
        "# Get a batch of training data\n",
        "#inputs, classes = next(iter(dataloaders['train']))\n",
        "\n",
        "# Make a grid from batch\n",
        "#out = torchvision.utils.make_grid(inputs)\n",
        "\n",
        "#imshow(out, title=[class_names[x] for x in classes])"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EaGdIpb6yEK3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_model(model, criterion, optimizer, scheduler, paciencia = 5,num_epochs=25):\n",
        "    since = time.time()\n",
        "    es = EarlyStopping(modo = 'min', paciencia=paciencia)\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
        "        print('-' * 10)\n",
        "\n",
        "        # Each epoch has a training and validation phase\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                model.train()  # Set model to training mode\n",
        "            else:\n",
        "                model.eval()   # Set model to evaluate mode\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            # Iterate over data.\n",
        "            for inputs, labels in dataloaders[phase]:\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                # zero the parameter gradients\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # forward\n",
        "                # track history if only in train\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    outputs = model(inputs)\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "                    loss = criterion(outputs, labels)\n",
        "\n",
        "                    # backward + optimize only if in training phase\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                # statistics\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "            #if phase == 'train':\n",
        "             #   scheduler.step()\n",
        "\n",
        "            epoch_loss = running_loss / dataset_sizes[phase]\n",
        "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
        "\n",
        "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
        "                phase, epoch_loss, epoch_acc))\n",
        "\n",
        "            # deep copy the model\n",
        "            \n",
        "            if phase == 'val' and epoch_acc > best_acc:\n",
        "                best_acc = epoch_acc\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "                \n",
        "            if es.deberia_parar(epoch_loss):\n",
        "                break\n",
        "            else:\n",
        "                continue\n",
        "        print()\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
        "        time_elapsed // 60, time_elapsed % 60))\n",
        "    print('Best val Acc: {:4f}'.format(best_acc))\n",
        "\n",
        "    # load best model weights\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OnfLu8-pyWwQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_ft = net.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Observe that all parameters are being optimized\n",
        "optimizer_ft = optim.Adadelta(model_ft.parameters())\n",
        "#optimizer_ft = optim.Adam(model_ft.parameters(), lr=1e-4, weight_decay=1e-5)\n",
        "#optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "\n",
        "# Decay LR by a factor of 0.1 every 7 epochs\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0lduRNZ_y5rm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 867
        },
        "outputId": "8cbce72e-1fc7-4917-b475-e4da6d24d2bd"
      },
      "source": [
        "model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler, paciencia = 7,\n",
        "                       num_epochs=20)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0/19\n",
            "----------\n",
            "train Loss: 0.7044 Acc: 0.2573\n",
            "val Loss: 0.6931 Acc: 0.3750\n",
            "\n",
            "Epoch 1/19\n",
            "----------\n",
            "train Loss: 0.6931 Acc: 0.2578\n",
            "val Loss: 0.6931 Acc: 0.3750\n",
            "\n",
            "Epoch 2/19\n",
            "----------\n",
            "train Loss: 0.6931 Acc: 0.2578\n",
            "val Loss: 0.6931 Acc: 0.3750\n",
            "\n",
            "Epoch 3/19\n",
            "----------\n",
            "train Loss: 0.6931 Acc: 0.2578\n",
            "val Loss: 0.6931 Acc: 0.3750\n",
            "\n",
            "Epoch 4/19\n",
            "----------\n",
            "train Loss: 0.6931 Acc: 0.2578\n",
            "\n",
            "Epoch 5/19\n",
            "----------\n",
            "train Loss: 0.6931 Acc: 0.2578\n",
            "\n",
            "Epoch 6/19\n",
            "----------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-3e9537c16c4a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler, paciencia = 7,\n\u001b[0;32m----> 2\u001b[0;31m                        num_epochs=20)\n\u001b[0m",
            "\u001b[0;32m<ipython-input-17-c55d50db7c67>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, criterion, optimizer, scheduler, paciencia, num_epochs)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0;31m# Iterate over data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataloaders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mphase\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m                 \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m                 \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    839\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    840\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 841\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    842\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    843\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    806\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    807\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 808\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    809\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    759\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    760\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 761\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    762\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    763\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    102\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m                     \u001b[0mtimeout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeadline\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonotonic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_readable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 414\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    415\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    909\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    910\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 911\u001b[0;31m                 \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    912\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    913\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileobj\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/selectors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    374\u001b[0m             \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 376\u001b[0;31m                 \u001b[0mfd_event_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    377\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZmfRZrrA1fdw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torchvision import models\n",
        "from torchsummary import summary\n",
        "\n",
        "summary(net, (3, 224, 224))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RfB0zOe8yQqP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def visualize_model(model, num_images=6):\n",
        "    was_training = model.training\n",
        "    model.eval()\n",
        "    images_so_far = 0\n",
        "    fig = plt.figure()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i, (inputs, labels) in enumerate(dataloaders['val']):\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "\n",
        "            for j in range(inputs.size()[0]):\n",
        "                images_so_far += 1\n",
        "                ax = plt.subplot(num_images//2, 2, images_so_far)\n",
        "                ax.axis('off')\n",
        "                ax.set_title('predicted: {}'.format(class_names[preds[j]]))\n",
        "                imshow(inputs.cpu().data[j])\n",
        "\n",
        "                if images_so_far == num_images:\n",
        "                    model.train(mode=was_training)\n",
        "                    return\n",
        "        model.train(mode=was_training)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dhg2-6Q01iK8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#torch.save(net.state_dict(), '/content/model.pt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "muqFSB2c4ugB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!cat > model.pt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OJJ_t2-T45KH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "visualize_model(net)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aKPUL-_8lBqQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!gpustat -p"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ro-It78NlHCp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}