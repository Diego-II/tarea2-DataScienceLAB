{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Pq9hTddORkUY"
   },
   "source": [
    "# 1. Carga de datos y librerias a usar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "id": "CWfEI8Oxnv6j",
    "outputId": "363068c8-50eb-4bb2-ff0c-e8d64a3d40ce"
   },
   "outputs": [],
   "source": [
    "#Estas lineas corren solo en google colab:\n",
    "import os.path \n",
    "try:\n",
    "  import google.colab\n",
    "  IN_COLAB = True\n",
    "except:\n",
    "  IN_COLAB = False\n",
    "if IN_COLAB:\n",
    "  if os.path.exists('/content/ChestXRay2017.zip'):\n",
    "    print(\"Datos ya descargados\")\n",
    "  else:\n",
    "    !wget https://data.mendeley.com/datasets/rscbjbr9sj/2/files/f12eaf6d-6023-432f-acc9-80c9d7393433/ChestXRay2017.zip\n",
    "    !unzip /content/ChestXRay2017.zip\n",
    "    !pip install gpustat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mfoNboyIolBF"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision.datasets.folder import default_loader\n",
    "\n",
    "# Intento de usar el train_model de https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html\n",
    "from __future__ import print_function, division\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "import torchvision\n",
    "#from torchvision.transforms.functional import convert_image_dtype\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "from torchsummary import summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SR3_62kTskvH"
   },
   "outputs": [],
   "source": [
    "# Torchvision transforms compose para carga de datos con transformacion:\n",
    "\n",
    "degrees = (-20,20)\n",
    "transformer = torchvision.transforms.Compose([        \n",
    "    torchvision.transforms.Resize(size = (224,224)),\n",
    "    torchvision.transforms.RandomHorizontalFlip(p=0.5),\n",
    "    torchvision.transforms.RandomRotation(degrees),\n",
    "    torchvision.transforms.ColorJitter(brightness=[1.2, 1.5]),\n",
    "    torchvision.transforms.ToTensor(), \n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iCrYK4I2SI8o"
   },
   "outputs": [],
   "source": [
    "# Usamos el loader por defecto de ImageFolder\n",
    "# Deja las imagenes con 3 capas\n",
    "from torchvision.datasets.folder import default_loader\n",
    "    \n",
    "import google.colab\n",
    "import os.path \n",
    "root = '/content/chest_xray/train/'\n",
    "train_dir = '/content/chest_xray/train/'\n",
    "test_dir = '/content/chest_xray/test/'\n",
    "\n",
    "data_train1=datasets.DatasetFolder(root = train_dir, loader =  default_loader, transform = transformer, extensions = 'jpeg')\n",
    "data_test1=datasets.DatasetFolder(root = test_dir, loader = default_loader, transform = transformer, extensions = 'jpeg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "OzpzG5SB7_An",
    "outputId": "ae4b0918-77d9-4e9b-ad97-908006de7750"
   },
   "outputs": [],
   "source": [
    "# 3\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Subset\n",
    "\n",
    "# split\n",
    "train_idx, val_idx = train_test_split(list(range(len(data_train1))),test_size=0.2)\n",
    "#data_train = Subset(data_train1, train_idx)\n",
    "#data_val   = Subset(data_train1,val_idx)\n",
    "\n",
    "class ReplicarMuestreoDePrueba(torch.utils.data.Sampler):\n",
    "    \n",
    "    def __init__(self,etiquetas_prueba, indices_val, etiquetas_val):\n",
    "        self.indices_val      = indices_val\n",
    "        #self.etiquetas_val    = etiquetas_val\n",
    "        self.prob_pneumonia   = sum(etiquetas_prueba)/len(etiquetas_prueba)\n",
    "        self.prob_normal      = 1-self.prob_pneumonia\n",
    "        print(self.prob_pneumonia,self.prob_normal)\n",
    "        self.prob_vector      = (np.array(etiquetas_val)==1)*self.prob_pneumonia+(np.array(etiquetas_val)==0)*self.prob_normal\n",
    "        print(self.prob_vector)\n",
    "        self.prob_vector = self.prob_vector*(1/sum(self.prob_vector))\n",
    "    def __iter__(self):\n",
    "        return iter(np.random.choice(self.indices_val,p=self.prob_vector))\n",
    "    \n",
    "etiquetas_prueba = data_test1.targets\n",
    "# indices_val = val_idx\n",
    "etiquetas_val = [data_train1.targets[i] for i in val_idx ] \n",
    "\n",
    "a=ReplicarMuestreoDePrueba(etiquetas_prueba,val_idx, etiquetas_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4ciYAMCOSZRx"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data.sampler import RandomSampler, SubsetRandomSampler\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "#data_train = DataLoader(data_train1,sampler=SubsetRandomSampler(train_idx))\n",
    "#data_val   = DataLoader(data_train1,sampler=ReplicarMuestreoDePrueba(etiquetas_prueba,val_idx, etiquetas_val))\n",
    "data_test  = DataLoader(data_test1,sampler=RandomSampler(data_test1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9V5TCHhPiEJz"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data.sampler import RandomSampler, SubsetRandomSampler\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "data_dir = '/content/chest_xray'\n",
    "bs = 16\n",
    "\n",
    "dataloaders = {\n",
    "    'train' : DataLoader(data_train1, \n",
    "                         sampler = SubsetRandomSampler(train_idx), \n",
    "                         batch_size = bs,\n",
    "                         num_workers=4\n",
    "                         ),\n",
    "    'val' : DataLoader(data_train1,\n",
    "                       #sampler = ReplicarMuestreoDePrueba(etiquetas_prueba,val_idx, etiquetas_val),\n",
    "                       sampler = SubsetRandomSampler(val_idx),\n",
    "                       batch_size = bs,\n",
    "                       num_workers=4\n",
    "                       )\n",
    "}\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YkUch_CXTM5D"
   },
   "source": [
    "# 2. Red VGG16DWSep."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "id": "slduMCm4TuGX",
    "outputId": "2a6b6d31-d0fe-4eff-fe64-c42365e6df91"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "torch.manual_seed(2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CxHrOK5h7_A2"
   },
   "outputs": [],
   "source": [
    "class DWSepConv2d(nn.Module):\n",
    "    \n",
    "    def __init__(self,in_channels, out_channels, kernel_size,padding,bias=True):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, in_channels,kernel_size,padding=padding,bias=bias)\n",
    "        self.conv2 = nn.Conv2d(in_channels, out_channels,kernel_size=1,padding=padding,bias=bias)\n",
    "    def forward(self,xb):\n",
    "        xb = F.relu(self.conv1(xb.float()))\n",
    "        xb = F.relu(self.conv2(xb)) \n",
    "        return xb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rtSek5x67_A6"
   },
   "outputs": [],
   "source": [
    "class VGG16DWSep(nn.Module):\n",
    "    \n",
    "    def __init__(self,in_channels):\n",
    "        super().__init__()\n",
    "        # bloque 1\n",
    "        self.conv1 = nn.Conv2d(in_channels,64,kernel_size=3,padding=1,stride=1)\n",
    "        self.conv2 = nn.Conv2d(64,64,kernel_size=3, padding=1, stride=1)\n",
    "        self.maxpool1 = nn.MaxPool2d(kernel_size=2,stride=2) \n",
    "        # bloque 2\n",
    "        self.dwconv3 = DWSepConv2d(64,128,kernel_size=3,padding=1)\n",
    "        self.dwconv4 = DWSepConv2d(128,128,kernel_size=3,padding=1)\n",
    "        self.maxpool2 = nn.MaxPool2d(kernel_size=2,stride=2)\n",
    "        # bloque 3        \n",
    "        self.dwconv5 = DWSepConv2d(128,256,kernel_size=3,padding=1)\n",
    "        self.batchnorm1 = nn.BatchNorm2d(256)\n",
    "        # bloque 4\n",
    "        self.dwconv6 = DWSepConv2d(256,256,kernel_size=3,padding=1)\n",
    "        self.batchnorm2 = nn.BatchNorm2d(256)\n",
    "        # bloque 5\n",
    "        self.dwconv7 = DWSepConv2d(256,256,kernel_size=3,padding=1)\n",
    "        self.maxpool3 = nn.MaxPool2d(kernel_size=2,stride=2)\n",
    "        # bloque 6\n",
    "        self.dwconv8 = DWSepConv2d(256,512,kernel_size=3,padding=1)\n",
    "        self.batchnorm3 = nn.BatchNorm2d(512)\n",
    "        # bloque 7\n",
    "        self.dwconv9 = DWSepConv2d(512,512,kernel_size=3,padding=1)\n",
    "        self.batchnorm4 = nn.BatchNorm2d(512)\n",
    "        # bloque 8\n",
    "        self.dwconv10 = DWSepConv2d(512,512,kernel_size=3,padding=1)\n",
    "        self.maxpool4 = nn.MaxPool2d(kernel_size=2,stride=2)\n",
    "        # bloque o1\n",
    "        self.flatten1 = nn.Flatten()\n",
    "        self.lin1 = nn.Linear(184832,1024)\n",
    "        self.drop1 = nn.Dropout(.7)\n",
    "        # bloque o2\n",
    "        self.lin2 = nn.Linear(1024,512)\n",
    "        self.drop2 = nn.Dropout(.5)\n",
    "        self.lin3 = nn.Linear(512,2)\n",
    "    \n",
    "    def forward(self,xb):\n",
    "      # bloque 1\n",
    "      xb = xb.view(-1, 3, 224, 224)\n",
    "      xb = F.relu(self.conv1(xb))\n",
    "      xb = F.relu(self.conv2(xb))\n",
    "      xb = self.maxpool1(xb)\n",
    "      # bloque 2\n",
    "      xb = F.relu(self.dwconv3(xb))\n",
    "      xb = F.relu(self.dwconv4(xb))\n",
    "      xb = self.maxpool2(xb)\n",
    "      # bloque 3\n",
    "      xb = F.relu(self.dwconv5(xb))\n",
    "      xb = F.relu(self.batchnorm1(xb))\n",
    "      # bloque 4\n",
    "      xb = F.relu(self.dwconv6(xb))\n",
    "      xb = F.relu(self.batchnorm2(xb))\n",
    "      # bloque 5\n",
    "      xb = F.relu(self.dwconv7(xb))\n",
    "      xb = self.maxpool3(xb)\n",
    "      # bloque 6\n",
    "      xb = F.relu(self.dwconv8(xb))\n",
    "      xb = F.relu(self.batchnorm3(xb))\n",
    "      # bloque 7\n",
    "      xb = F.relu(self.dwconv9(xb))\n",
    "      xb = F.relu(self.batchnorm4(xb))\n",
    "      # bloque 8\n",
    "      xb = F.relu(self.dwconv10(xb))\n",
    "      xb = self.maxpool4(xb)\n",
    "      #print(xb.shape)\n",
    "      # bloque o1\n",
    "      xb = self.flatten1(xb)\n",
    "      xb = F.relu(self.lin1(xb))\n",
    "      xb = self.drop1(xb)\n",
    "      # bloque o2\n",
    "      xb = F.relu(self.lin2(xb))\n",
    "      xb = self.drop2(xb)\n",
    "      xb = F.relu(self.lin3(xb))\n",
    "      return xb.view(-1, xb.size(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8f4uQ-0MT6WF"
   },
   "source": [
    "## Importar red VGG16 ya entrenada para transferir pesos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gN9I9dKK7_A-",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Descargamos la red vgg16\n",
    "try: \n",
    "  summary(vgg16.cuda(),(3,224,244))\n",
    "except:\n",
    "  vgg16 = torchvision.models.vgg16(pretrained=True, progress=True)\n",
    "  summary(vgg16.cuda(),(3,224,244))\n",
    "\n",
    "# Congelamos los pesos de la red VGG16:\n",
    "for param in vgg16.parameters():\n",
    "  param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qUbCizC5T36s"
   },
   "outputs": [],
   "source": [
    "# Se quiere la capa 0 y la 2, que son las dos primeras convolucionales:\n",
    "pesos_dict = {\n",
    "    'conv1' : vgg16.features[0],\n",
    "    'conv2' : vgg16.features[2]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ntEcjPB7UQhW"
   },
   "outputs": [],
   "source": [
    "# Instanciamos una reg VGG16DWSep:\n",
    "model = VGG16DWSep(in_channels = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7f0DTbuDUZmB"
   },
   "outputs": [],
   "source": [
    "# Transferencia de pesos:\n",
    "model.conv1.weight = pesos_dict['conv1'].weight\n",
    "model.conv2.weight = pesos_dict['conv2'].weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0IS7g5P3Uwzp"
   },
   "outputs": [],
   "source": [
    "# Congelamos los pesos transferidos en la red instanciada:\n",
    "model.conv1.requires_grad_ = False\n",
    "model.conv2.requires_grad_ = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "x_b5cB1ezmiX"
   },
   "outputs": [],
   "source": [
    "summary(model.cuda(), (3, 224,224))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ih5UVYQwVuqD"
   },
   "source": [
    "## Heuristica EarlyStopping:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tUdbW4DvVkfD"
   },
   "outputs": [],
   "source": [
    "# Clase EarlyStopping\n",
    "# Se requiere la libreria numpy!!\n",
    "import numpy  as np\n",
    "class EarlyStopping():\n",
    "  '''\n",
    "  Regularization heuristic:\n",
    "\n",
    "  '''\n",
    "  def __init__(self, modo='min', paciencia=5, porcentaje:bool = False, tol=0):\n",
    "    '''\n",
    "    Arguments:\n",
    "    ---------\n",
    "    modo: 'min' o 'max'. Si se debe minimizar o maximizar la metrica objetivo\n",
    "    paciancia: Cantidad de epocas en la que la metrica puede empeorar\n",
    "    porcentaje: si la diferencia es relativa (true) o absoluta\n",
    "    tol: diferencia minima que debe existir con respecto la mejor metrica ya\n",
    "        observada  para considerar si existe un empeoramiento del desempeno\n",
    "    '''\n",
    "    self.modo = modo\n",
    "    self.paciencia  = paciencia\n",
    "    self.porcentaje = porcentaje\n",
    "    self.best = np.Inf if self.modo == 'min' else -np.Inf\n",
    "    self.contador = 0\n",
    "    self.tol = tol\n",
    "\n",
    "  \n",
    "  def __compareMin(self, metrica_validacion):\n",
    "    if self.porcentaje:      \n",
    "      # Si la dif relativa es mayor a la tolerada: actualizar contador:\n",
    "      if metrica_validacion < (1-self.tol)*self.best:\n",
    "        self.contador = 0\n",
    "        self.best = metrica_validacion\n",
    "        return True\n",
    "      else:\n",
    "        self.contador +=1\n",
    "        return False\n",
    "    else:\n",
    "      if metrica_validacion < self.best - self.tol:\n",
    "        self.best = metrica_validacion\n",
    "        self.contador = 0\n",
    "        return True\n",
    "      else:\n",
    "        self.contador += 1\n",
    "        return False\n",
    "    \n",
    "  def __compareMax(self, metrica_validacion):\n",
    "    if self.porcentaje:\n",
    "        # Si la dif relativa es mayor a la tolerada: actualizar contador:\n",
    "      if metrica_validacion > (1+self.tol)*self.best:\n",
    "        self.contador = 0\n",
    "        self.best = metrica_validacion\n",
    "        return True\n",
    "      else:\n",
    "        self.contador +=1\n",
    "        return False\n",
    "    else:\n",
    "      if metrica_validacion > self.best + self.tol:\n",
    "        self.best = metrica_validacion\n",
    "        self.contador = 0\n",
    "        return True\n",
    "      else:\n",
    "        self.contador += 1\n",
    "        return False        \n",
    "\n",
    "  # Es necesaria la anotacion??\n",
    "  #@classmethod\n",
    "  def __mejor(self, metrica_validacion):\n",
    "    '''\n",
    "    Compara @metrica_validacion con la mejor ya observada segun las \n",
    "    especificaciones de porcentaje y modo. \n",
    "    '''\n",
    "    if self.modo == 'min':\n",
    "      # Comparar segun el modo y porcentaje:\n",
    "      if self.__compareMin(metrica_validacion):\n",
    "        return True\n",
    "      else:\n",
    "        return False\n",
    "    else:\n",
    "      # Comparar segun el modo y porcentaje:\n",
    "      if self.__compareMax(metrica_validacion):\n",
    "        return True\n",
    "      else:\n",
    "        return False\n",
    "\n",
    "  #@classmethod\n",
    "  def deberia_parar(self, metrica_validacion):\n",
    "    if not self.__mejor(metrica_validacion) and self.contador >= self.paciencia:\n",
    "      return True\n",
    "    else:\n",
    "      return False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xMLp_hClV9VC"
   },
   "source": [
    "## Train model: \n",
    "Basado en metodo fit implementado en los notebooks de catedra:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3teBgTyCqDVn"
   },
   "outputs": [],
   "source": [
    "def loss_batch(model, loss_func, xb, yb, opt=None):\n",
    "    loss = loss_func(model(xb), yb)\n",
    "\n",
    "    if opt is not None:\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "\n",
    "    return loss.item(), len(xb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nYW8cZDcP8sA"
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "\n",
    "def register(res_list):\n",
    "    '''Obtiene la perdida promedio y su desviacion estandar en batches.'''\n",
    "    \n",
    "    losses, nums = zip(*res_list)\n",
    "    \n",
    "    N = np.sum(nums)\n",
    "    loss_mean = np.sum(np.multiply(losses, nums))/N\n",
    "    loss_std = np.sqrt(np.sum(np.multiply((losses-loss_mean)**2, nums))/(N-1))\n",
    "    \n",
    "    return loss_mean, loss_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "x0lEHvlsP8sn"
   },
   "outputs": [],
   "source": [
    "def accuracy(y_hat_b,yb):\n",
    "    \n",
    "    preds = torch.argmax(torch.softmax(y_hat_b,dim = 1),dim=1)\n",
    "    counts = (preds == yb)*1.0\n",
    "    \n",
    "    return torch.mean(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vTUH6mEpZJvS"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def train_model(model, loss_func, opt, metric = None, modo = 'min', paciencia = 5, num_epochs=20, print_leap = 1):\n",
    "  since = time.time()\n",
    "  es = EarlyStopping(modo = 'max', paciencia=paciencia)\n",
    "  best_model_wts = copy.deepcopy(model.state_dict())\n",
    "  best_acc = 0.0\n",
    "  if metric is None:\n",
    "    metric = accuracy\n",
    "\n",
    "  learning_data_loss = pd.DataFrame(\n",
    "  columns=['epoch', 'train_mean', 'train_std', 'val_mean', 'val_std'])\n",
    "  learning_data_acc = pd.DataFrame(\n",
    "  columns=['epoch', 'train_mean', 'train_std', 'val_mean', 'val_std'])\n",
    "\n",
    "  for epoch in range(num_epochs):\n",
    "    print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "    print('-' * 10)\n",
    "\n",
    "    # Each epoch has a training and validation phase\n",
    "    train_res_loss = []\n",
    "    train_res_acc = []\n",
    "    for phase in ['train', 'val']:\n",
    "      if phase == 'train':\n",
    "        model.train()  # Set model to training mode\n",
    "\n",
    "        for inputs, labels in dataloaders[phase]:\n",
    "          inputs = inputs.to(device)\n",
    "          labels = labels.to(device)\n",
    "\n",
    "          # Para entrenar se usa la funcion de perdida\n",
    "          loss_batch(model, loss_func, inputs, labels, opt)\n",
    "\n",
    "          # Para almacenar se puede usar una metrica\n",
    "          train_res_loss.append(loss_batch(model, loss_func, inputs, labels))\n",
    "          train_res_acc.append(loss_batch(model, metric, inputs, labels))\n",
    "      else:\n",
    "        model.eval()   # Set model to evaluate mode\n",
    "        for inputs, labels in dataloaders[phase]:\n",
    "          inputs = inputs.to(device)\n",
    "          labels = labels.to(device)\n",
    "\n",
    "          with torch.no_grad():\n",
    "            val_res_loss = [\n",
    "                loss_batch(model, loss_func, inputs, labels) \n",
    "            ]\n",
    "            val_res_acc = [\n",
    "                  loss_batch(model, metric, inputs, labels)          \n",
    "            ]\n",
    "    # Register loss func\n",
    "    val_loss, val_loss_std = register(val_res_loss)\n",
    "    train_loss, train_loss_std = register(train_res_loss)\n",
    "    # Register acc\n",
    "    val_acc, val_acc_std = register(val_res_acc)\n",
    "    train_acc, train_acc_std = register(train_res_acc)\n",
    "\n",
    "    if epoch % print_leap == 0:\n",
    "      print('Epoca:', epoch, '- val loss:', val_loss, '- train loss:', train_loss)\n",
    "      print('Epoca:', epoch, '- val acc:', val_acc, '- train acc:', train_acc)\n",
    "      print('-'*20)\n",
    "\n",
    "    learning_data_loss = learning_data_loss.append(\n",
    "                    {\n",
    "                    'epoch': epoch,\n",
    "                    'train_mean': train_loss,\n",
    "                    'train_std': train_loss_std,\n",
    "                    'val_mean': val_loss,\n",
    "                    'val_std': val_loss_std\n",
    "                    },\n",
    "                    ignore_index=True)\n",
    "    \n",
    "    learning_data_acc = learning_data_acc.append(\n",
    "                    {\n",
    "                    'epoch': epoch,\n",
    "                    'train_mean': train_acc,\n",
    "                    'train_std': train_acc_std,\n",
    "                    'val_mean': val_acc,\n",
    "                    'val_std': val_acc_std\n",
    "                    },\n",
    "                    ignore_index=True)\n",
    "\n",
    "     \n",
    "    if phase == 'val' and val_acc > best_acc:\n",
    "      best_acc = val_acc\n",
    "      best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "    if es.deberia_parar(val_acc):\n",
    "      break\n",
    "    else:\n",
    "      continue\n",
    "    print()\n",
    "\n",
    "  time_elapsed = time.time() - since\n",
    "  print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "  time_elapsed // 60, time_elapsed % 60))\n",
    "\n",
    "  return model, best_model_wts,learning_data_loss, learning_data_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oRr7HczrvCu4"
   },
   "outputs": [],
   "source": [
    "model_ft = model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = optim.Adam(model_ft.parameters(), lr=1e-4, weight_decay=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "u0EResQ0uIs_"
   },
   "outputs": [],
   "source": [
    "model_ft, best_model,train_loss, train_acc = train_model(model_ft, criterion, optimizer_ft,  paciencia = 5,\n",
    "                       num_epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TWmMteSAP8sw"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def show_learning_curves(learning_data, y_name = 'Metrica',leaps = 1):\n",
    "    '''Genera curvas de aprendizaje dado data dataframe resultado de fit().'''\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=[10, 7])\n",
    "    ax.grid()\n",
    "\n",
    "\n",
    "    epcs = learning_data['epoch'][::leaps]\n",
    "    val_loss_lower = (learning_data['val_mean'] -\n",
    "                      learning_data['val_std'])[::leaps]\n",
    "\n",
    "    val_loss_upper = (learning_data['val_mean'] +\n",
    "                      learning_data['val_std'])[::leaps]\n",
    "\n",
    "    train_loss_lower = (learning_data['train_mean'] -\n",
    "                        learning_data['train_std'])[::leaps]\n",
    "    train_loss_upper = (learning_data['train_mean'] +\n",
    "                        learning_data['train_std'])[::leaps]\n",
    "\n",
    "    ax.plot(epcs,\n",
    "            learning_data['val_mean'][::leaps],\n",
    "            'o--',\n",
    "            color=\"g\",\n",
    "            label=\"Validation\")\n",
    "\n",
    "    ax.fill_between(epcs, val_loss_lower, val_loss_upper, alpha=0.1, color='g')\n",
    "\n",
    "    ax.plot(epcs,\n",
    "            learning_data['train_mean'][::leaps],\n",
    "            'o--',\n",
    "            color=\"r\",\n",
    "            label=\"Train\")\n",
    "\n",
    "    ax.fill_between(epcs, train_loss_lower, train_loss_upper, alpha=0.1, color='r')\n",
    "\n",
    "    ax.set_title('Curva de Aprendizaje', fontsize=25)\n",
    "    ax.set_xlabel('Epocas', fontsize=15)\n",
    "    ax.set_ylabel(y_name, fontsize=15)\n",
    "    ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qT91SJI0Y-f5"
   },
   "outputs": [],
   "source": [
    "show_learning_curves(train_loss,'CrossEntropy Loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "teI3i9VqZBr-"
   },
   "outputs": [],
   "source": [
    "show_learning_curves(train_acc, 'Accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1yP-SPvriZhr"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Tarea2_V3",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
