{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tarea 2\n",
    "## Laboratorio de Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# librerías usadas\n",
    "import torch\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.utils import make_grid\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Carga y transformación de Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1\n",
    "# iniciar datos\n",
    "def load(path):\n",
    "    image_rgb =Image.open(path).convert(\"RGB\")\n",
    "    return image_rgb\n",
    "\n",
    "div= np.iinfo('uint8').max # maximo valor de tipo uint8\n",
    "transformers=transforms.Compose(\n",
    "                [transforms.Resize([224,224]),\n",
    "                 transforms.RandomRotation(degrees=20),\n",
    "                 transforms.RandomHorizontalFlip(),\n",
    "                 transforms.ColorJitter(brightness=[1.2, 1.5]),\n",
    "                 transforms.ToTensor()\n",
    "                ])\n",
    "\n",
    "# Usamos el loader por defecto de ImageFolder\n",
    "# Deja las imagenes con 3 capas\n",
    "from torchvision.datasets.folder import default_loader\n",
    "    \n",
    "data_train1=datasets.DatasetFolder(root='chest_xray/train',loader=default_loader,transform=transformers, extensions='jpeg')\n",
    "data_test1=datasets.DatasetFolder(root='chest_xray/test',loader=default_loader,transform=transformers, extensions='jpeg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "To Do : \n",
    "\n",
    "loaders\n",
    "\n",
    "Perfilamiento de tiempo de cómputo \n",
    "\n",
    "Comparación de las librerias pytorch PIL skimage opencv\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2\n",
    "\n",
    "classes_train1 = data_train1.targets\n",
    "classes_test1 = data_test1.targets\n",
    "\n",
    "pneumonia_train=int(sum(classes_train1))\n",
    "normal_train=len(classes_train1)-pneumonia_train\n",
    "\n",
    "\n",
    "pneumonia_test=int(sum(classes_test1))\n",
    "normal_test=len(classes_test1)-pneumonia_test\n",
    "\n",
    "labels = 'Normal', 'Pneumonia'\n",
    "sizes_train = [normal_train, pneumonia_train]\n",
    "\n",
    "sizes_test = [normal_test, pneumonia_test]\n",
    "\n",
    "fig, axs = plt.subplots(1,2)\n",
    "axs[0].pie(sizes_train,labels=labels,explode=(0,0.1),autopct='%1.1f%%')\n",
    "axs[1].pie(sizes_test,labels=labels,explode =(0,0.1),autopct='%1.1f%%')\n",
    "\n",
    "axs[0].set_title('Train set')\n",
    "axs[1].set_title('Test set')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Subset\n",
    "\n",
    "# split\n",
    "train_idx, val_idx = train_test_split(list(range(len(data_train1))),test_size=0.2)\n",
    "#data_train = Subset(data_train1, train_idx)\n",
    "#data_val   = Subset(data_train1,val_idx)\n",
    "\n",
    "class ReplicarMuestreoDePrueba(torch.utils.data.Sampler):\n",
    "    \n",
    "    def __init__(self,etiquetas_prueba, indices_val, etiquetas_val):\n",
    "        self.indices_val      = indices_val\n",
    "        #self.etiquetas_val    = etiquetas_val\n",
    "        self.prob_pneumonia   = sum(etiquetas_prueba)/len(etiquetas_prueba)\n",
    "        self.prob_normal      = 1-self.prob_pneumonia\n",
    "        self.prob_vector      = [ int((etiquetas_val[i]==1 )*self.prob_pneumonia+\n",
    "                                 (etiquetas_val[i]==0)*self.prob_normal)\n",
    "                                for i in range(len(etiquetas_prueba))\n",
    "                                ]\n",
    "    def __iter__(self):\n",
    "        return iter(np.random.choice(self.indices_val,p=self.prob_vector))\n",
    "    \n",
    "etiquetas_prueba = data_test1.targets\n",
    "# indices_val = val_idx\n",
    "etiquetas_val = [data_train1.targets[i] for i in val_idx ] \n",
    "\n",
    "a=ReplicarMuestreoDePrueba(etiquetas_prueba,val_idx, etiquetas_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4\n",
    "from torch.utils.data.sampler import RandomSampler, SubsetRandomSampler\n",
    "\n",
    "data_train = DataLoader(data_train1,sampler=SubsetRandomSampler(train_idx))\n",
    "data_val   = DataLoader(data_train1,sampler=ReplicarMuestreoDePrueba(etiquetas_prueba,val_idx, etiquetas_val))\n",
    "data_test  = DataLoader(data_test1,sampler=RandomSampler(data_test1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Sampler no apaña ?\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Redes convolucionales profundas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1 \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "torch.manual_seed(2020)\n",
    "\n",
    "\n",
    "class DWSepConv2d(nn.Module):\n",
    "    \n",
    "    def __init__(self,in_channels, out_channels, kernel_size,padding,bias=True,stride=1):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels,kernel_size,padding=padding,stride=stride,bias=bias)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels,kernel_size=1,padding=padding,bias=bias,stride=stride)\n",
    "    def forward(self,xb):\n",
    "        xb = F.relu(self.conv1(xb.float()))\n",
    "        xb = F.relu(self.conv2(xb)) \n",
    "        return xb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2\n",
    "\n",
    "class VGG16DWSep(nn.Module):\n",
    "    \n",
    "    def __init__(self,in_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels,64,kernel_size=3,padding=1,stride=1)\n",
    "        self.conv2 = nn.Conv2d(64,64,kernel_size=3, padding=1, stride=1)\n",
    "        self.maxpool1 = nn.MaxPool2d(kernel_size=2,stride=2) # verificar los tamaños\n",
    "        self.dwconv3 = DWSepConv2d(64,128,kernel_size=3,padding=1,stride=1)\n",
    "        self.dwconv4 = DWSepConv2d(128,128,kernel_size=3,padding=1,stride=1)\n",
    "        self.maxpool2 = nn.MaxPool2d(kernel_size=2,stride=2)\n",
    "        self.dwconv5 = DWSepConv2d(128,256,kernel_size=3,padding=1,stride=1)\n",
    "        self.batchnorm1 = nn.BatchNorm2d(256)\n",
    "        self.dwconv6 = DWSepConv2d(256,256,kernel_size=3,padding=1,stride=1)\n",
    "        self.batchnorm2 = nn.BatchNorm2d(256)\n",
    "        self.dwconv7 = DWSepConv2d(256,256,kernel_size=3,padding=1,stride=1)\n",
    "        self.maxpool3 = nn.MaxPool2d(kernel_size=2,stride=2)\n",
    "        self.dwconv8 = DWSepConv2d(256,512,kernel_size=3,padding=1,stride=1)\n",
    "        self.batchnorm3 = nn.BatchNorm2d(512)\n",
    "        self.dwconv9 = DWSepConv2d(512,512,kernel_size=3,padding=1,stride=1)\n",
    "        self.batchnorm4 = nn.BatchNorm2d(512)\n",
    "        self.dwconv10 = DWSepConv2d(512,512,kernel_size=3,padding=1,stride=1)\n",
    "        self.maxpool4 = nn.MaxPool2d(kernel_size=2,stride=2)\n",
    "        self.flatten1 = nn.Flatten()\n",
    "        self.lin1 = nn.Linear(512,1024)\n",
    "        self.drop1 = nn.Dropout(.7)\n",
    "        self.lin2 = nn.Linear(1024,512)\n",
    "        self.drop2 = nn.Dropout(.5)\n",
    "        self.lin3 = nn.Linear(512,2)\n",
    "    \n",
    "    def forward(self,xb):\n",
    "        xb = xb.view(-1,3,224,224).float()\n",
    "        xb = F.relu(self.conv1(xb))\n",
    "        xb = F.relu(self.conv2(xb))\n",
    "        xb = F.relu(self.maxpool1(xb))\n",
    "        xb = F.relu(self.dwconv3(xb))\n",
    "        xb = F.relu(self.dwconv4(xb))\n",
    "        xb = F.relu(self.maxpool2(xb))\n",
    "        xb = F.relu(self.dwconv5(xb))\n",
    "        xb = F.relu(self.batchnorm1(xb))\n",
    "        xb = F.relu(self.dwconv6(xb))\n",
    "        xb = F.relu(self.batchnorm2(xb))\n",
    "        xb = F.relu(self.dwconv7(xb))\n",
    "        xb = F.relu(self.maxpool3(xb))\n",
    "        xb = F.relu(self.dwconv8(xb))\n",
    "        xb = F.relu(self.batchnorm3(xb))\n",
    "        xb = F.relu(self.dwconv9(xb))\n",
    "        xb = F.relu(self.mbatchnorm4(xb))\n",
    "        xb = F.relu(self.dwconv10(xb))\n",
    "        xb = F.relu(self.flatten1(xb))\n",
    "        xb = F.relu(self.lin1(xb))\n",
    "        xb = F.relu(self.drop1(xb))\n",
    "        xb = F.relu(self.lin2(xb))\n",
    "        xb = F.relu(self.drop2(xb))\n",
    "        xb = F.relu(self.lin3(xb))\n",
    "        \n",
    "        \n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}