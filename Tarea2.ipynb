{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tarea 2\n",
    "## Laboratorio de Datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Carga y transformación de Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# librerías usadas\n",
    "import torch\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.utils import make_grid\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import PIL\n",
    "from skimage import io\n",
    "from skimage.color import gray2rgb\n",
    "\n",
    "# 1\n",
    "# iniciar datos\n",
    "\n",
    "\"\"\"\n",
    "Funciones loaders \n",
    "- pil_loader        :   carga con pil\n",
    "- skimage_loader    :   carga con skimage\n",
    "- opencv_loader     :   carga con opencv\n",
    "\"\"\"\n",
    "def opencv_loader(path):\n",
    "    bgr_image = cv2.imread(path)\n",
    "    return bgr_image\n",
    "def pil_loader(path):\n",
    "    image_rgb =Image.open(path).convert(\"RGB\")\n",
    "    return image_rgb\n",
    "def skimage_loader(path):\n",
    "    image=io.imread(path)\n",
    "    return gray2rgb(image)\n",
    "\n",
    "div= np.iinfo('uint8').max # maximo valor de tipo uint8\n",
    "transformers=transforms.Compose(\n",
    "                [transforms.Resize([224,224]),\n",
    "                #transforms.Normalize(mean=0,std = div, inplace = True),\n",
    "                 transforms.RandomRotation(degrees=20),\n",
    "                 transforms.RandomHorizontalFlip(),\n",
    "                 transforms.ColorJitter(brightness=[1.2, 1.5]),\n",
    "                 transforms.ToTensor() # ToTensor convierte a valores entre 0 y 1\n",
    "                ])\n",
    "\n",
    "# Usamos el loader por defecto de ImageFolder\n",
    "# Deja las imagenes con 3 capas\n",
    "from torchvision.datasets.folder import default_loader\n",
    "    \n",
    "data_train1=datasets.DatasetFolder(root='chest_xray/train',loader=default_loader,transform=transformers, extensions='jpeg')\n",
    "data_test1=datasets.DatasetFolder(root='chest_xray/test',loader=default_loader,transform=transformers, extensions='jpeg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "To Do : \n",
    "\n",
    "\n",
    "Perfilamiento de tiempo de cómputo \n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2\n",
    "\n",
    "classes_train1 = data_train1.targets\n",
    "classes_test1 = data_test1.targets\n",
    "\n",
    "pneumonia_train=int(sum(classes_train1))\n",
    "normal_train=len(classes_train1)-pneumonia_train\n",
    "\n",
    "\n",
    "pneumonia_test=int(sum(classes_test1))\n",
    "normal_test=len(classes_test1)-pneumonia_test\n",
    "\n",
    "labels = 'Normal', 'Pneumonia'\n",
    "sizes_train = [normal_train, pneumonia_train]\n",
    "\n",
    "sizes_test = [normal_test, pneumonia_test]\n",
    "\n",
    "fig, axs = plt.subplots(1,2)\n",
    "axs[0].pie(sizes_train,labels=labels,explode=(0,0.1),autopct='%1.1f%%')\n",
    "axs[1].pie(sizes_test,labels=labels,explode =(0,0.1),autopct='%1.1f%%')\n",
    "\n",
    "axs[0].set_title('Train set')\n",
    "axs[1].set_title('Test set')\n",
    "\n",
    "\n",
    "plt.show()\n",
    "plt.savefig('distribucionTrainTest.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Subset\n",
    "\n",
    "# split\n",
    "train_idx, val_idx = train_test_split(list(range(len(data_train1))),test_size=0.2)\n",
    "#data_train = Subset(data_train1, train_idx)\n",
    "#data_val   = Subset(data_train1,val_idx)\n",
    "\n",
    "class ReplicarMuestreoDePrueba(torch.utils.data.Sampler):\n",
    "    \n",
    "    def __init__(self,etiquetas_prueba, indices_val, etiquetas_val):\n",
    "        self.indices_val      = indices_val\n",
    "        #self.etiquetas_val    = etiquetas_val\n",
    "        self.prob_pneumonia   = sum(etiquetas_prueba)/len(etiquetas_prueba)\n",
    "        self.prob_normal      = 1-self.prob_pneumonia\n",
    "        self.prob_vector      = [ int((etiquetas_val[i]==1 )*self.prob_pneumonia+\n",
    "                                 (etiquetas_val[i]==0)*self.prob_normal)\n",
    "                                for i in range(len(etiquetas_prueba))\n",
    "                                ]\n",
    "    def __iter__(self):\n",
    "        return iter(np.random.choice(self.indices_val,p=self.prob_vector))\n",
    "    \n",
    "etiquetas_prueba = data_test1.targets\n",
    "# indices_val = val_idx\n",
    "etiquetas_val = [data_train1.targets[i] for i in val_idx ] \n",
    "\n",
    "a=ReplicarMuestreoDePrueba(etiquetas_prueba,val_idx, etiquetas_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4\n",
    "from torch.utils.data.sampler import RandomSampler, SubsetRandomSampler\n",
    "\n",
    "data_train = DataLoader(data_train1,sampler=SubsetRandomSampler(train_idx))\n",
    "data_val   = DataLoader(data_train1,sampler=ReplicarMuestreoDePrueba(etiquetas_prueba,val_idx, etiquetas_val))\n",
    "data_test  = DataLoader(data_test1,sampler=RandomSampler(data_test1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# P2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1 \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "torch.manual_seed(2020)\n",
    "\n",
    "\n",
    "class DWSepConv2d(nn.Module):\n",
    "    \n",
    "    def __init__(self,in_channels, out_channels, kernel_size,padding,bias=True,stride=1):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels,kernel_size,padding=padding,stride=stride,bias=bias)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels,kernel_size=1,padding=padding,bias=bias,stride=stride)\n",
    "    def forward(self,xb):\n",
    "        xb = F.relu(self.conv1(xb.float()))\n",
    "        xb = F.relu(self.conv2(xb)) \n",
    "        return xb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2\n",
    "\n",
    "class VGG16DWSep(nn.Module):\n",
    "    \n",
    "    def __init__(self,in_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels,64,kernel_size=3,padding=1,stride=1)\n",
    "        self.conv2 = nn.Conv2d(64,64,kernel_size=3, padding=1, stride=1)\n",
    "        self.maxpool1 = nn.MaxPool2d(kernel_size=2,stride=2) # verificar los tamaños\n",
    "        self.dwconv3 = DWSepConv2d(64,128,kernel_size=3,padding=1,stride=1)\n",
    "        self.dwconv4 = DWSepConv2d(128,128,kernel_size=3,padding=1,stride=1)\n",
    "        self.maxpool2 = nn.MaxPool2d(kernel_size=2,stride=2)\n",
    "        self.dwconv5 = DWSepConv2d(128,256,kernel_size=3,padding=1,stride=1)\n",
    "        self.batchnorm1 = nn.BatchNorm2d(256)\n",
    "        self.dwconv6 = DWSepConv2d(256,256,kernel_size=3,padding=1,stride=1)\n",
    "        self.batchnorm2 = nn.BatchNorm2d(256)\n",
    "        self.dwconv7 = DWSepConv2d(256,256,kernel_size=3,padding=1,stride=1)\n",
    "        self.maxpool3 = nn.MaxPool2d(kernel_size=2,stride=2)\n",
    "        self.dwconv8 = DWSepConv2d(256,512,kernel_size=3,padding=1,stride=1)\n",
    "        self.batchnorm3 = nn.BatchNorm2d(512)\n",
    "        self.dwconv9 = DWSepConv2d(512,512,kernel_size=3,padding=1,stride=1)\n",
    "        self.batchnorm4 = nn.BatchNorm2d(512)\n",
    "        self.dwconv10 = DWSepConv2d(512,512,kernel_size=3,padding=1,stride=1)\n",
    "        self.maxpool4 = nn.MaxPool2d(kernel_size=2,stride=2)\n",
    "        self.flatten1 = nn.Flatten()\n",
    "        self.lin1 = nn.Linear(512,1024)\n",
    "        self.drop1 = nn.Dropout(.7)\n",
    "        self.lin2 = nn.Linear(1024,512)\n",
    "        self.drop2 = nn.Dropout(.5)\n",
    "        self.lin3 = nn.Linear(512,2)\n",
    "    \n",
    "    def forward(self,xb):\n",
    "        xb = xb.view(-1,3,224,224).float()\n",
    "        xb = F.relu(self.conv1(xb))\n",
    "        xb = F.relu(self.conv2(xb))\n",
    "        xb = F.relu(self.maxpool1(xb))\n",
    "        xb = F.relu(self.dwconv3(xb))\n",
    "        xb = F.relu(self.dwconv4(xb))\n",
    "        xb = F.relu(self.maxpool2(xb))\n",
    "        xb = F.relu(self.dwconv5(xb))\n",
    "        xb = F.relu(self.batchnorm1(xb))\n",
    "        xb = F.relu(self.dwconv6(xb))\n",
    "        xb = F.relu(self.batchnorm2(xb))\n",
    "        xb = F.relu(self.dwconv7(xb))\n",
    "        xb = F.relu(self.maxpool3(xb))\n",
    "        xb = F.relu(self.dwconv8(xb))\n",
    "        xb = F.relu(self.batchnorm3(xb))\n",
    "        xb = F.relu(self.dwconv9(xb))\n",
    "        xb = F.relu(self.mbatchnorm4(xb))\n",
    "        xb = F.relu(self.dwconv10(xb))\n",
    "        xb = F.relu(self.flatten1(xb))\n",
    "        xb = F.relu(self.lin1(xb))\n",
    "        xb = F.relu(self.drop1(xb))\n",
    "        xb = F.relu(self.lin2(xb))\n",
    "        xb = F.relu(self.drop2(xb))\n",
    "        xb = F.relu(self.lin3(xb))\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3\n",
    "import os\n",
    "try:\n",
    "    from urllib.request import URLopener\n",
    "except ImportError:\n",
    "    from urllib import URLopener\n",
    "\n",
    "# Download VGG-16 weights from PyTorch\n",
    "vgg_url = 'https://download.pytorch.org/models/vgg16_bn-6c64b313.pth'\n",
    "if not os.path.isfile('./vgg16_bn-6c64b313.pth'):\n",
    "    weights = URLopener().retrieve(vgg_url, './vgg16_bn-6c64b313.pth')\n",
    "\n",
    "vgg16_weights = torch.load('./vgg16_bn-6c64b313.pth')\n",
    "\n",
    "# Descargamos la red vgg16\n",
    "vgg16 = torchvision.models.vgg16(pretrained=True, progress=True)\n",
    "\n",
    "\n",
    "from torchsummary import summary\n",
    "summary(vgg16.cuda(),(3,224,244))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Se deben obtener las dos primeras capas de convolucion de la red VGG16\n",
    "for i in range(3):\n",
    "  print(vgg16.features[i])\n",
    "\n",
    "\n",
    "vgg16.state_dict\n",
    "\n",
    "# Se quiere la capa 0 y la 2, que son las dos primeras convolucionales:\n",
    "pesos_dict = {\n",
    "    'conv1' : vgg16.features[0],\n",
    "    'conv2' : vgg16.features[2]\n",
    "}\n",
    "\n",
    "\n",
    "net = VGG16DWSep(in_channels = 3)\n",
    "\n",
    "#intento de traspaso de pesos:\n",
    "net.conv1 = pesos_dict['conv1']\n",
    "net.conv2 = pesos_dict['conv2']\n",
    "\n",
    "\n",
    "# Congelamos los pesos de la red vgg16\n",
    "for param in vgg16.parameters():\n",
    "  param.requires_grad = False\n",
    "\n",
    "# Congelamos los pesos de las dos primeras capas convoluvionales de la red \n",
    "# (capas que se transfirieron):\n",
    "net.conv1.requires_grad_ = False\n",
    "net.conv2.requires_grad_ = False\n",
    "\n",
    "\n",
    "net.cuda()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# P3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1\n",
    "\n",
    "# librerías usadas\n",
    "import torch\n",
    "from torchvision import models\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.utils import make_grid\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# iniciar datos\n",
    "def load(path):\n",
    "    image_rgb =Image.open(path).convert(\"RGB\")\n",
    "    return image_rgb\n",
    "\n",
    "\n",
    "\n",
    "# transformaciones compose\n",
    "transformers=transforms.Compose([transforms.Resize([229,229]),\n",
    "                transforms.CenterCrop(229),\n",
    "                 transforms.ToTensor(),\n",
    "                 transforms.Normalize(mean=[0.485,0.456,0.406],std=[0.229,0.224,0.225], inplace = True)\n",
    "                ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 2\n",
    "from keras.applications.imagenet_utils import decode_predictions\n",
    "inception_v3_net = models.inception_v3(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "inception_v3_net.eval()\n",
    "filename = 'dog.jpg'\n",
    "input_image = Image.open(filename)\n",
    "input_tensor = transformers(input_image).float()\n",
    "input_batch = input_tensor.unsqueeze(0)\n",
    "inception_v3_net(input_batch)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}