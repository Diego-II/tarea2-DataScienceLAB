{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "P3.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "iHVugQSjzPHo"
      },
      "source": [
        "### P3. Interpretabilidad.\n",
        "****************************\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "hyfQrJhrz19N"
      },
      "source": [
        "   1. Parte 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "4H8ZwV6izWuP",
        "colab": {}
      },
      "source": [
        "# librerías usadas\n",
        "import torch\n",
        "from torchvision import models\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.utils import make_grid\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# iniciar datos\n",
        "def load(path):\n",
        "    image_rgb =Image.open(path).convert(\"RGB\")\n",
        "    return image_rgb\n",
        "\n",
        "\n",
        "\n",
        "# transformaciones compose\n",
        "transformers=transforms.Compose(\n",
        "    [transforms.Resize(299),\n",
        "     transforms.CenterCrop(229),\n",
        "     transforms.ToTensor(),\n",
        "     transforms.Normalize(mean=[0.485,0.456,0.406],std=[0.229,0.224,0.225])         \n",
        "    ]\n",
        ")"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ZIFqB6Kez6OH"
      },
      "source": [
        "  2. Parte 2."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "wXKD8_5Lz5kp",
        "colab": {}
      },
      "source": [
        "#imagen sde prueba\n",
        "%%capture\n",
        "import urllib\n",
        "url, filename = (\"https://github.com/pytorch/hub/raw/master/dog.jpg\", \"dog.jpg\")\n",
        "try: urllib.URLopener().retrieve(url, filename)\n",
        "except: urllib.request.urlretrieve(url, filename)\n",
        "\n",
        "### cargo el modelo inception_v3\n",
        "inception_v3_net = torch.hub.load('pytorch/vision:v0.6.0', 'inception_v3', pretrained=True)\n",
        "\n",
        "###genero el modelo \n",
        "inception_v3_net.eval()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "819KCCLGQF0L",
        "colab": {}
      },
      "source": [
        "#transformo los datos\n",
        "input_image = Image.open(filename)\n",
        "plt.imshow(np.asarray(input_image))\n",
        "\n",
        "input_tensor = transformers(input_image)\n",
        "input_batch = input_tensor.unsqueeze(0)\n",
        "\n",
        "# # move the input and model to GPU for speed if available\n",
        "# if torch.cuda.is_available():\n",
        "#     input_batch = input_batch.to('cuda')\n",
        "#     model.to('cuda')\n",
        "\n",
        "# with torch.no_grad():\n",
        "#   output = model(input_batch)\n",
        "\n",
        "#predicción del modelo\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    input_batch = input_batch.to('cuda')\n",
        "    inception_v3_net.to('cuda')\n",
        "    \n",
        "with torch.no_grad():\n",
        "  out = inception_v3_net(input_batch).cpu()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "HweTNHiR5Frc",
        "colab": {}
      },
      "source": [
        "from keras.applications.imagenet_utils import decode_predictions\n",
        "labs = decode_predictions(out.numpy(),top=1)\n",
        "\n",
        "print('Nombre de la clase predicha: ', labs[0][0][0],'\\n')\n",
        "print('Descripción de la clase: ', labs[0][0][1],'\\n')\n",
        "print('Valor del puntaje de la red: ',labs[0][0][2])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Fev38v99Rvdr"
      },
      "source": [
        "  3. Segmente la imagen de control utilizando la función ```slic``` del módulo ```skimage.segmentation```, para los parámetros ```start_label=0```, ```n_segments=80```. El resultado de la segmentación es un arreglo de dimensión 299&times;299 que asigna una categoría para cada píxel de la imágen procesada. Todos los pixeles en la imágen que comparten etiqueta conforman un súper-píxel dentro de la imágen. Utilice la función ```mark_boundaries``` del módulo ```skimage.segmentation``` en conjunto con ```imshow``` del módulo ```skimage.io``` para visualizar los bordes inducidos por el conjunto de super-pixeles. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "fsJDfLBu1DnH",
        "colab": {}
      },
      "source": [
        "import skimage.segmentation as sks\n",
        "from skimage.io import imshow as ims\n",
        "\n",
        "imagen_np = np.asarray(input_image)\n",
        "imagen_seg = sks.slic(imagen_np, n_segments=80)\n",
        "\n",
        "print('Imágen segmentada:\\n')\n",
        "ims(imagen_seg)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "j216xhC-6IZ-",
        "colab": {}
      },
      "source": [
        "print('Imagen original:\\n')\n",
        "plt.imshow(imagen_np)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gjsizs1LVV7b",
        "colab": {}
      },
      "source": [
        "imagen_bnd = sks.mark_boundaries(imagen_np,imagen_seg, color = (0,0,0), outline_color=(0,1,0))\n",
        "print('Imágen con los super-pixeles marcados en sus bordes:\\n')\n",
        "ims(imagen_bnd)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "hW7CJQCeZbXM"
      },
      "source": [
        "Al representar una imágen _x_ por medio de la presencia y ausencia de súper-pixeles se logra una representación interpretable _x'_ según un vector de entradas binarias.\n",
        "\n",
        "Genere perturbaciones en la imágen de control, para esto siga los siguientes pasos:\n",
        "\n",
        "  4. Defina un número de _perturbaciones_ a realizar (al menos 1000). Cada perturbación consiste en un arreglo binario, donde cada componente es asociada a un súper-pixel. Estos arreglos serán las representaciones interpretables de la imagen de control (_x'_ asociado a _x_). Considere cada entrada del arreglo de perturbaciones como una variable **Bernoulli** con _p=0.5_."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "i-dcuXsgWjDy",
        "colab": {}
      },
      "source": [
        "#probaremos con 1000 perturbaciones\n",
        "n_per = 1000\n",
        "ind = np.array([(i in imagen_seg) for i in range(80)])\n",
        "n_clases = len(ind[ind == True])\n",
        "\n",
        "M = np.zeros([n_clases,n_per])\n",
        "\n",
        "#binomial(1,p)=bernoulli(p), asigno en una matriz de n_clases x n_perturbaciones donde cada fila corresponde al valor de la clase en esa perturbación.\n",
        "np.random.seed(10)\n",
        "for i in range(n_per):\n",
        "  M[:,i] = np.random.binomial(1,0.5,n_clases)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "SjIDDtLlk9gd"
      },
      "source": [
        "  5. Genere tantas versiones perturbadas de la imagen de control como perturbaciones haya conseguido. Obtener una imagen perturbada consiste en asignar el valor 0 en cada canal de color en aquellos píxeles cuyos super-pixeles asociados tengan su componente nula en el vector de perturbaciones. Obtenga una visualización de una imágen perturbada."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-z9uB0FidkeN",
        "colab": {}
      },
      "source": [
        "#generando imágenes perturbadas.\n",
        "\n",
        "n_x, n_y, n_colores= np.shape(imagen_np) #coordenadas de la imagen normal.\n",
        "\n",
        "imag_perturb = [] #guardar imágenes perturbadas. guardar en formato Image\n",
        "\n",
        "\n",
        "for p in range(n_per):\n",
        "  #para cada perturbación hago una copia de la imagen\n",
        "  image_copy = imagen_np.copy()\n",
        "  for i in range(n_x):\n",
        "    for j in range(n_y):\n",
        "      pos = imagen_seg[i,j]\n",
        "      if M[pos,p] == 0:\n",
        "        image_copy[i,j,:] = [0,0,0]\n",
        "  \n",
        "  imag_perturb.append(image_copy)\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "N2vT2gWZgxZl",
        "colab": {}
      },
      "source": [
        "# Mostrar una imágen cualquiera\n",
        "plt.imshow(imag_perturb[425])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "h7CLIJq-uavt"
      },
      "source": [
        "  6. Haga predicciones sobre las imágenes perturbadas utilizando la red ```inception_v3```. Asocie el valor 1 como etiqueta a las imágenes perturbadas  que sean clasificadas a la misma categoría de la imágen de control y 0 en caso contrario, el arreglo binario correspondiente se denotará _y_."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JHyaMPjJsFOw",
        "colab": {}
      },
      "source": [
        "#función que evalúa una imágen y la compara con una etiqueta según la predicción\n",
        "def Evaluación_red(imag_array, nombre_cat, print_ = False):\n",
        "  input_image = Image.fromarray(imag_array)\n",
        "  input_tensor = transformers(input_image)\n",
        "  input_batch = input_tensor.unsqueeze(0)\n",
        "\n",
        "  if torch.cuda.is_available():\n",
        "    input_batch = input_batch.to('cuda')\n",
        "    inception_v3_net.to('cuda')\n",
        "    \n",
        "  with torch.no_grad():\n",
        "    out = inception_v3_net(input_batch).cpu()\n",
        "  \n",
        "  labs = decode_predictions(out.numpy(),top=1)\n",
        "  \n",
        "  if print_:\n",
        "    print(labs[0][0][0])\n",
        "  \n",
        "  if labs[0][0][0] == nombre_cat:\n",
        "    return 1\n",
        "  else:\n",
        "    return 0"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7FJ7mn1Kv8mZ",
        "colab": {}
      },
      "source": [
        "# nombre de la categoría correcta.\n",
        "label = labs[0][0][0]\n",
        "label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "orM37hh6wAih",
        "colab": {}
      },
      "source": [
        "#Prueba de la función\n",
        "Evaluación_red(imag_perturb[20], label, print_ = True) #no acertó"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "CzHX9rwQwN-8",
        "colab": {}
      },
      "source": [
        "#Generación del vector Y\n",
        "y =[]\n",
        "for i in range(n_per):\n",
        "  y.append(Evaluación_red(imag_perturb[i],label))"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "HGjUZGFvwvL-"
      },
      "source": [
        "  7. Calcule &pi;<sub>_x_</sub> según la expresión (3). Para ello, obtenga la distancia del coseno entre las perturbaciones asociadas a cada imágen perturbada y el vector de perturbación de la imágen de control _x_ según lo indica (4)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "A9qXTARF7tQZ"
      },
      "source": [
        "Tomamos\n",
        "$$\n",
        "x' = (1,\\cdots,1)\n",
        "$$\n",
        "como el vector que identifica a la imagen original $x$. Entonces, si $N$ es la cantidad de clases encontradas en la segmentación, entonces:\n",
        "\n",
        "$$\n",
        "x' \\in \\{0,1\\}^N,\\hspace{0.4cm}\\text{y }\\hspace{0.4cm}||x'|| = \\sqrt{N}\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-PuPavEjwm7c",
        "colab": {}
      },
      "source": [
        "# Definimos la distancia.\n",
        "def dist_x(z):\n",
        "  n = len(z)\n",
        "  a = np.sum(z)\n",
        "  norm_x = np.sqrt(n)\n",
        "  norm_z = np.sqrt(np.sum(z**2))\n",
        "\n",
        "  d = 1 - (a/(norm_x*norm_z))\n",
        "  if norm_z == 0:\n",
        "    return 1\n",
        "  else:\n",
        "    return d\n",
        "\n",
        "# Definimos la distancia coseno:\n",
        "\n",
        "def pi_x(z,sigma):\n",
        "  d = dist_x(z)\n",
        "\n",
        "  return np.exp((-d**2) / (sigma**2))"
      ],
      "execution_count": 129,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XuKEK9Tcwp_9",
        "colab": {}
      },
      "source": [
        "# Primera perturbación:\n",
        "per_0 = M[:,0]\n",
        "np.shape(per_0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "FJ2MQvsS-cXf",
        "colab": {}
      },
      "source": [
        "# Prueba de las funciones anteriores para sigma=1.\n",
        "pi_x(per_0, sigma=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "HBg3X6Xs_CYi"
      },
      "source": [
        "Una vez obtenido el conjunto de reprsentaciones para la imágen de control $x$ y el vector de pesos asociados &pi;<sub>$x$</sub>, se pasa a minimizar la función de fidelidad, para esto:\n",
        "\n",
        "  8. Genere un conjunto de entrenamiento $D_p$. Este consta de vectores de perturbación como observaciones. La variable de respuesta será el arreglo $y$ generado anteriormente."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "58iGNS7z-n8t",
        "colab": {}
      },
      "source": [
        "D_p = [M[:,i] for i in range(n_per)]\n",
        "\n",
        "# y definido anteriormente."
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Cy1SlME4AxxU"
      },
      "source": [
        "  9. Utilice la clase ```LogisticRegression``` del módulo ```sklearn.linear_model``` para entrenar un clasificador sobre el conjunto de entrenamiento $D_p$. Haga uso de $\\pi_x$ al momento de usar el método ```.fit()```. ¿Es posible agregar una medida de complejidad $\\Omega(g)$ con este esquema?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vodu3W2IAw6J",
        "colab": {}
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "sigma = 0.25\n",
        "weight = np.array([pi_x(D_p[i],sigma) for i in range(n_per)])\n",
        "\n",
        "reg = LogisticRegression().fit(D_p,y, sample_weight=weight)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7n-y8KuDE92d",
        "colab": {}
      },
      "source": [
        "reg.coef_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "itYrAE8wOmO1"
      },
      "source": [
        "   10. Utilice los coeficientes del clasificador anterior para inferir los súper-índices de mayor importancia en la clasificación de la imágen de control."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "YogKmq5rO7Cj"
      },
      "source": [
        "Dado que la regresión logística vincula a la variable $X$ con la respuesta $Y$ de una forma no lineal, no se analizarán a los coeficientes por el tamaño de su magnitud (módulo) como en la regresión lineal. En cambio, la importancia de la variable estará dada por un factor exponencial del coeficiente. Es decir, si $\\beta_i$ es el coeficiente asociado al súper-píxel $i$, entonces la importancia de tal súperpixel se puede medir mediante:\n",
        "\n",
        "$$\n",
        "e^{\\beta_i}\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "fL_AFNK9O6LX",
        "colab": {}
      },
      "source": [
        "coef = np.array(reg.coef_[0])\n",
        "\n",
        "#región de corte al valor de ln(1.4)\n",
        "plt.figure(figsize = (10,7))\n",
        "plt.plot(coef, np.exp(coef), '*', label = 'Importancia del coeficiente en el modelo')\n",
        "plt.axhline(y=1.4, xmin=0, xmax=1, color = 'r')\n",
        "plt.legend()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "QIVzU3azS7LR",
        "colab": {}
      },
      "source": [
        "sup_pix = coef[coef > np.log(1.4)]\n",
        "Importantes = [i for i in range(54) if coef[i] in sup_pix]\n",
        "print(Importantes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "o4xZj5sKUZ7P",
        "colab": {}
      },
      "source": [
        "# Generamos una imágen que contenga a los superpixéles más importantes:\n",
        "M_reg = np.zeros(54)\n",
        "for i in range(54):\n",
        "  if i in Importantes:\n",
        "    M_reg[i] = 1\n",
        "\n",
        "\n",
        "image_new = imagen_np.copy()\n",
        "for i in range(n_x):\n",
        "  for j in range(n_y):\n",
        "    pos = imagen_seg[i,j]\n",
        "    if M_reg[pos] == 0:\n",
        "      image_new[i,j,:] = [0,0,0]"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "y3WITBGHV-vJ",
        "colab": {}
      },
      "source": [
        "plt.imshow(image_new)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "-VA9sffMYfov"
      },
      "source": [
        "A medida que aumentamos el criterio de elección de los super-pixeles (mayores coeficientes) notamos que los pixeles que se mantienen siempre entre aquellos que el modelo necesita ver para tomar una buena desición son aquellos que están cercanos a la cara del perro (en este caso). Esto es explicado por el nivel de detalle (y por lo tanto, de información) que contiene la imágen y que la diferencia de otras que puedan poseer colores u otras características similares."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "hSpIAvmmZtaU"
      },
      "source": [
        "La segmentación antes utilizada se hace de _manera espacial_. Es decir, se realiza una clusterización sobre la escala de grises según su posición en la imágen. Del procediminto recién explicado para implementar **LIME** reemplace la etapa de segmentación de la imágen por 2 segmentaciones espaciales utilizando 2 modelos de clustering a su elección, para ello:\n",
        "\n",
        "  11. Clusterice sobre un conjunto de entrenamiento $X$ con $299^2$ observaciones, es decir, una observación por píxel en la imagen del control escalada. Cada Observación de $X$ consta de 3 componentes, donde la primera y segunda son espaciales (posición del píxel en la imágen) y la última es el valor de intensidad asociado al píxel (escala de grises). Utilice los cluster descubiertos para generar súper-píxeles."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "mjrhteMrWE9n",
        "colab": {}
      },
      "source": [
        "# Algoritmo clusterizador a ocupar: K-means\n",
        "# Luego de cargar la imágen en 2d (escala de grises), se genera una matriz de datos donde la fila corresponde al vecrtor [posición_x, posición_y, color_de_(x,y)]\n",
        "\n",
        "from sklearn.cluster import KMeans\n",
        "newsize = (299,299)\n",
        "image_ = np.asarray(Image.open(filename).resize(newsize).convert('RGB'))\n",
        "image_2d = np.mean(image_, axis=2, dtype=np.uint)\n",
        "np.shape(image_2d)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y1zbSa96Kmqr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_km = []\n",
        "\n",
        "for i in range(299):\n",
        "  for j in range(299):\n",
        "    X_km.append([i,j, image_2d[i,j]])"
      ],
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "aXBjJvJRcrTK",
        "colab": {}
      },
      "source": [
        "kmean = KMeans().fit_predict(X_km)\n",
        "np.shape(kmean) # vector de etiquetas para cada vector de X_km, necesario reordenar en matrix de 299x299 para graficar vecindades"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i3082df4NHAG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "kmean_pix = kmean.reshape([299,299])\n",
        "kmean_pix.max() +1 #cantidad de clases"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3OM4rmLldAZv",
        "colab": {}
      },
      "source": [
        "imagen_bnd2 = sks.mark_boundaries(image_,kmean_pix, color = (0,0,0), outline_color=(0,1,0))\n",
        "ims(imagen_bnd2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k6WIyvc8ROhQ",
        "colab_type": "text"
      },
      "source": [
        "Podemos observar que la mayor cantidad de clusters se concentran en la cara del perro, lugar que, según el modelo anterior, era imprescindible para que la red pueda reconocer la imágen. Clusterización reconoce el pasto, el fondo y el cuerpo del perro como secciones distintas (esto es un poco evidente, puesto que los colores que predominaban en la imágen eran notoriamente distintos, por lo tanto el valor en la imágen también).\n",
        "Veamos la importancia de cada cluster visto como segmentaciones de los pasos anteriores.\n",
        "\n",
        "  12. Aplique el esquema **LIME** desarrollado anteriormente sobre sus súper-pixeles."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IltxlP8fPLGE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#probaremos con 1000 perturbaciones denuevo\n",
        "\n",
        "n_clases_km = kmean_pix.max() +1\n",
        "\n",
        "M2 = np.zeros([n_clases_km,n_per])\n",
        "\n",
        "#binomial(1,p)=bernoulli(p), asigno en una matriz de n_clases x n_perturbaciones donde cada fila corresponde al valor de la clase en esa perturbación.\n",
        "np.random.seed(10)\n",
        "for i in range(n_per):\n",
        "  M2[:,i] = np.random.binomial(1,0.5,n_clases_km)"
      ],
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wp3N_b-iVsea",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#generando imágenes perturbadas.\n",
        "\n",
        "imag_perturb_km = [] #guardar imágenes perturbadas. guardar en formato Image\n",
        "\n",
        "\n",
        "for p in range(n_per):\n",
        "  #para cada perturbación hago una copia de la imagen\n",
        "  image_copy = image_.copy()\n",
        "  for i in range(299):\n",
        "    for j in range(299):\n",
        "      pos = kmean_pix[i,j]\n",
        "      if M2[pos,p] == 0:\n",
        "        image_copy[i,j,:] = [0,0,0]\n",
        "  \n",
        "  imag_perturb_km.append(image_copy)\n"
      ],
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yCS8AW0mWLcV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Mostrar una imágen cualquiera \n",
        "plt.imshow(imag_perturb_km[640])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_MhH1xZ8XeXz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Generación del vector Y\n",
        "y_km =[]\n",
        "for i in range(n_per):\n",
        "  y_km.append(Evaluación_red(imag_perturb_km[i],label))"
      ],
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y5sz1tZWZEjT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "D_km = [M2[:,i] for i in range(n_per)]\n",
        "weight_km = np.array([pi_x(D_km[i],sigma) for i in range(n_per)])\n",
        "\n",
        "reg_km = LogisticRegression().fit(D_km,y_km, sample_weight=weight_km)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mIMk8F4MZhUQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "coef_km = np.array(reg_km.coef_[0])\n",
        "\n",
        "#región de corte al valor de ln(1.4)\n",
        "plt.figure(figsize = (10,7))\n",
        "plt.plot(coef_km, np.exp(coef_km), '*', label = 'Importancia del coeficiente en el modelo')\n",
        "# plt.axhline(y=1.4, xmin=0, xmax=1, color = 'r')\n",
        "plt.legend()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jd9oeRVsby5T",
        "colab_type": "text"
      },
      "source": [
        "Podemos ver sólo un coeficiente positivo (mayor a 6), por lo tanto al aplicar la exponencial, separa brúscamente este coeficiente de los demáses que los sitúa por debajo de 1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kJxFgO6bZrUX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sup_pix_km = coef_km[coef_km > np.log(100)]\n",
        "Importantes_km = [i for i in range(8) if coef_km[i]> np.log(100)]\n",
        "print(Importantes_km,'\\n')\n",
        "\n",
        "# Generamos una imágen que contenga a los superpixéles más importantes:\n",
        "\n",
        "coef_image = image_.copy()\n",
        "for i in range(299):\n",
        "  for j in range(299):\n",
        "    if kmean_pix[i,j] not in Importantes_km:\n",
        "      coef_image[i,j,:] = [0,0,0]\n",
        "\n",
        "plt.imshow(coef_image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PLzuZ333gc6g",
        "colab_type": "text"
      },
      "source": [
        "Al igual que la parte anterior, el aspecto más importante de la imágen es la forma que presenta la cara del perro, sin embargo (y no es muy notorio) no considera detalles de la cada, como los ojos, la nariz y el ocico. Esto puede ser por el color negro que presentan, lo que hace que anular el cluster en esa zona no presente mayor diferencia en el modelo, pues el color no cambia drásticamente como el resto del cuerpo. Bajo esa lógica es claro que el modelo de regesión no dará peso de importancia a aquellos cluster."
      ]
    }
  ]
}